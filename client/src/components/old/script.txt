import React from "react";
import { io } from "https://cdn.socket.io/4.4.1/socket.io.esm.min.js";

const script = () => {
var rec;//Recorder.js object
var input;//MediaStreamAudioSourceNode we'll be recording
var audioContext;
var stashedAudio;

const socket = io();
// connection
socket.on("connect", () => {
    console.log('connect');
});

socket.on("tts_success", (value) => {
    console.log('tts_success', value['result']);
    ttsSuccessFunction(value['result']);
});

socket.on("server_msg", (value) => {
    console.log('server_msg', value);
    playMessage(value);
});

socket.on("audio_answer", (value) => {
    console.log('audio answer');
    playMessage(value);
});


$(document).ready(function () {

    $('#startCb').change(function () {
        toggleRecording()
    });
    console.log('document ready');

    // shim for AudioContext when it's not avb.
    var AudioContext = window.AudioContext || window.webkitAudioContext;

    //new audio context to help us record
    audioContext = new AudioContext();

    $("#testId").on("click", playMessage2);

});

function toggleRecording() {
    let isChecked = $('#startCb').prop("checked");
    if (isChecked) {
        //start
        $('#startCbLabel').text("Stop");
        startRecording();
    } else {
        //stop
        $('#startCbLabel').text("Start");
        stopRecording();
    }
    console.log($('#startCb').prop("checked"));
}

function startRecording() {

    // We're using the standard promise based getUserMedia()
    // https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia 

    navigator.mediaDevices
        .getUserMedia({
            audio: true,
            video: false
        })
        .then(function (stream) {
            console.log(
                "mic ready, start recording"
            );

            //fix for https://developers.google.com/web/updates/2017/09/autoplay-policy-changes#webaudio
            audioContext.resume();
            input = audioContext.createMediaStreamSource(stream);

            // Create the Recorder object and configure to record mono sound (1 channel)
            // Wit AI only accepts mono
            rec = new Recorder(input, { numChannels: 1 });

            //start the recording process
            rec.record();
            console.log("Recording started");
        })
        .catch(function (err) {
            //if there was an error getting the mic
            console.log("error getting the mic:  " + err);
        });
}

function stopRecording() {

    if (rec) {
        rec.stop(); //stop microphone access
        console.log("Recording stopped");
        rec.exportWAV(storeAudio);
    }
}

function storeAudio(audioBlob) {
    // sending an event
    socket.emit("stt", audioBlob);
}

function ttsSuccessFunction(data) {
    let conf = parseFloat(data.confidence)
    if (data.success == false) {
        console.log('successFunction:false');
    } else {
        console.log('successFunction:true');
    }
    $('#response').prepend('<p>' + JSON.stringify(data.original) + '</p>');
    $('#response').prepend('<p>Text:' + data.text + ' <b>intent:' + data.intent + ' </b>@ ' + conf.toFixed(4) + '</p>');

    playMessage(data);
}
function playMessage2() {
    socket.emit("get_audio");
}

function playMessage(value) {
    console.log('playmessage');
    var data = value['audio_file'];
    var blob = new Blob([data]);
    var URL = window.URL || window.webkitURL;
    var url = URL.createObjectURL(blob);
    var sound = new Audio(url);
    sound.play();

}

return (

);

}

export default script;
